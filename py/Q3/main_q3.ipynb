{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d8be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 09:46:58.145600: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-11 09:46:58.832822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-11 09:47:00.201251: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import sys,os \n",
    "sys.path.append('/home/benr/ACT/CW2/py')\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import get_data,split_data_torch,evaluate,plot_train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dfe2d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "#Ensure CUDA is available. \n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b027a04",
   "metadata": {},
   "source": [
    "# Question 3, Using Data Augmentation to improve a CNN \n",
    "\n",
    "In this Notebook we will explore how image roatation and normalising image data can imporve the Convolutional neural network we created in Q2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ded9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benr/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n",
      "torch.Size([17736, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "# get the data from functions.py\n",
    "images,labels = get_data()\n",
    "# convert images to pytorch tnesors\n",
    "images = torch.from_numpy(images)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24745340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17736, 3, 256, 256])\n",
      "tensor([0.1675, 0.1626, 0.1589])\n",
      "tensor([0.1287, 0.1180, 0.1116])\n"
     ]
    }
   ],
   "source": [
    "# Move channels: (N,H,W,C) -> (N,C,H,W)\n",
    "images = images.permute(0, 3, 1, 2)      \n",
    "# standardise \n",
    "images = images.float() / 255.0    \n",
    "# The mean and standard deviation will be used later for normalisation   \n",
    "mean = images.mean(dim=[0,2,3])\n",
    "std = images.std(dim=[0,2,3])\n",
    "print(images.shape)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993d68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Galaxy_CNN(nn.Module):\n",
    "    def __init__(self, inCH, nCL):  \n",
    "        super(Galaxy_CNN, self).__init__()\n",
    "        # conv blocks\n",
    "        self.conv1 = nn.Conv2d(3, inCH, kernel_size=7, stride=1, padding=4)\n",
    "        # batchnorm is a way of normalising the activation values\n",
    "        self.bn1   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(inCH, inCH*2, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(inCH*2, inCH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #dropout is a way of 'turning off' some nodes temporarily, to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        # fully connected final layer \n",
    "        self.lin = nn.Linear(inCH*16**2, nCL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward section passes the batch through the graph\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))# conv1 -> batchnorm -> relu -> pooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))# conv2 -> batchnorm -> relu -> pooling \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))# conv3 -> batchnorm -> relu -> pooling\n",
    "        x = self.dropout(x) \n",
    "        #change shpae of tensor for linear layer (batch size,total features)    \n",
    "        x = x.view(x.size(0), -1)    \n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe1137",
   "metadata": {},
   "source": [
    "The kinds of data agumentation we want to implement take place in the training function, so for this question we will define the training function in this notebook rather than in functions.py, \n",
    "\n",
    "Since the evaluate() function is unchanged this will still be called from functions.py\n",
    "\n",
    "This code block also includes the random_rotate function, this function will implement a rotatrion on a certrain percentage of the image chosen by the user. The function carries out rotations of $90^o$, $180^o$ or $270^o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c624d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rotate some images at 90 degree angles  \n",
    "def random_rotate(imgs,p):\n",
    "   # only rotate images half of the time \n",
    "   if torch.rand(1).item() > p:\n",
    "      return imgs \n",
    "   s = imgs.size(0)\n",
    "   n90 = torch.randint(1,4,(s,), device=imgs.device)\n",
    "   rotated_img = []\n",
    "   for img,k in zip(imgs,n90):\n",
    "      rotated_img.append(torch.rot90(img,k = int(k),dims=(1,2)))\n",
    "   return torch.stack(rotated_img,dim =0) \n",
    "\n",
    "def train(model,trainLoader,testLoader,mean_tensor,std_tensor,criterion,optimizer\n",
    "          ,device,n_epoch):\n",
    "  early_stop = 10 \n",
    "  stop = 0\n",
    "  best_acc = 0.0 \n",
    "  trn_accs = []\n",
    "  tst_accs = []\n",
    "  for e in range(n_epoch):\n",
    "    #use model in training mode \n",
    "    model.train()\n",
    "    #increment loss for each image \n",
    "    running_loss = 0.0\n",
    "    # number of correct labels\n",
    "    correct = 0\n",
    "    # total number of samples \n",
    "    total = 0\n",
    "\n",
    "\n",
    "    for imgs,lbl in trainLoader:\n",
    "      # move image to GPU\n",
    "      imgs = imgs.to(device)\n",
    "      imgs = (imgs - mean_tensor) / std_tensor \n",
    "      #rotate images at random\n",
    "      imgs = random_rotate(imgs,0.55\n",
    "      )\n",
    "      #move label to GPU \n",
    "      labels = lbl.to(device)\n",
    "      #clear old gradients \n",
    "      optimizer.zero_grad()\n",
    "      # predict labels \n",
    "      outputs = model(imgs)\n",
    "      # workout the loss for the prediction \n",
    "      loss = criterion(outputs,labels)\n",
    "      # use backpropagation to calculate new weights \n",
    "      loss.backward()\n",
    "      # update weights \n",
    "      optimizer.step()\n",
    "      # get batch loss \n",
    "      running_loss += loss.item() * imgs.size(0)\n",
    "      # return position of most likely catagory for each image in batch \n",
    "      _,preds = torch.max(outputs,1)\n",
    "      # count the correctly predicted samples \n",
    "      correct += (preds == labels).sum().item()\n",
    "      # increae the total samples \n",
    "      total += labels.size(0)\n",
    "    # calculate train_loss for epoch \n",
    "    trn_loss = running_loss / total\n",
    "    # calculate train accuracy \n",
    "    trn_acc = correct / total \n",
    "    trn_accs.append(trn_acc)\n",
    "    # test trained model \n",
    "    test_acc = evaluate(model, testLoader,mean_tensor, std_tensor, device)\n",
    "    tst_accs.append(test_acc)\n",
    "    if test_acc > best_acc:\n",
    "       best_acc = test_acc\n",
    "       torch.save(model.state_dict(), \"best_model_q3.pt\")\n",
    "       print(f\"Saved new best model (acc={best_acc:.4f})\")\n",
    "       stop = 0 \n",
    "    else:\n",
    "       stop += 1 \n",
    "    if stop == early_stop:\n",
    "      plot_train(e,trn_accs,tst_accs)\n",
    "      break \n",
    "    print(f\"Epoch {e+1}/{n_epoch} \"\n",
    "        f\"Train loss: {trn_loss:.4f}  \"\n",
    "        f\"Train acc: {trn_acc:.3f}  \"\n",
    "        f\"Test acc: {test_acc:.3f}\")\n",
    "  if stop < early_stop:\n",
    "   plot_train(e,trn_accs,tst_accs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa9a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split tensor into training and test sets (see functions.py)\n",
    "I = np.arange(len(labels))\n",
    "xtrn,xtst,ytrn,ytst = split_data_torch(images,labels,I)\n",
    "\n",
    "\n",
    "# match images and labels in a torch dataset \n",
    "train_ds = TensorDataset(xtrn, ytrn)\n",
    "test_ds  = TensorDataset(xtst, ytst)\n",
    "\n",
    "\n",
    "\n",
    "#create train and test loaders for training\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=5, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "    test_ds, batch_size=5, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ead91da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# number of catagories \n",
    "num_classes = len(labels.unique())\n",
    "# tell the computer to use the GPU via CUDA \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#The network model \n",
    "model = Galaxy_CNN(128,num_classes).to(device)\n",
    "\n",
    "''' The criterion is the loss function, in this case we are using cross entropy. \n",
    "This function asigns probabilities to each catagory, for example [0,1,0,0...] might be\n",
    "a spiral galaxy. Cross entropy then measures how close the outputs are to this true \n",
    "probability.'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# the method of gradient decent used in backpropogation. \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=10**-3,weight_decay=1e-4)\n",
    "\n",
    "#for normalisation \n",
    "mean_tensor = mean.view(1,3,1,1).to(device)\n",
    "std_tensor = std.view(1,3,1,1).to(device)\n",
    "\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964eb9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model (acc=0.4205)\n",
      "Epoch 1/70 Train loss: 2.1886  Train acc: 0.344  Test acc: 0.421\n",
      "Saved new best model (acc=0.5351)\n",
      "Epoch 2/70 Train loss: 1.5109  Train acc: 0.457  Test acc: 0.535\n",
      "Saved new best model (acc=0.5644)\n",
      "Epoch 3/70 Train loss: 1.3851  Train acc: 0.502  Test acc: 0.564\n"
     ]
    }
   ],
   "source": [
    "# begin training \n",
    "train(model, train_loader,test_loader,  \n",
    "      mean_tensor,std_tensor,\n",
    "      criterion, \n",
    "      optimizer, device, \n",
    "      n_epoch=70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203424ba",
   "metadata": {},
   "source": [
    "These results are an improvement... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Galaxy_CNN_adaptive(nn.Module):\n",
    "    def __init__(self, inCH, nCL):  \n",
    "        super(Galaxy_CNN_adaptive, self).__init__()\n",
    "        # conv blocks\n",
    "        self.conv1 = nn.Conv2d(3, inCH, kernel_size=7, stride=1, padding=4)\n",
    "        # batchnorm is a way of normalising the activation values\n",
    "        self.bn1   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(inCH, inCH*2, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(inCH*2, inCH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #dropout is a way of 'turning off' some nodes temporarily, to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        # fully connected final layer \n",
    "        self.lin = nn.Linear(inCH, nCL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward section passes the batch through the graph\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))# conv1 -> batchnorm -> relu -> pooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))# conv2 -> batchnorm -> relu -> pooling \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))# conv3 -> batchnorm -> relu -> pooling\n",
    "        x = self.gap(x)     \n",
    "        x = self.dropout(x) \n",
    "        #change shpae of tensor for linear layer (batch size,total features)    \n",
    "        x = x.view(x.size(0), -1)    \n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac0f9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: unspecified launch failure\nSearch for `cudaErrorLaunchFailure' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_adpt = \u001b[43mGalaxy_CNN_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m optimizer = torch.optim.Adam(model_adpt.parameters(),lr=\u001b[32m10\u001b[39m**-\u001b[32m3\u001b[39m,weight_decay=\u001b[32m1e-4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ACT/CW2/venv1/lib/python3.12/site-packages/torch/nn/modules/module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ACT/CW2/venv1/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ACT/CW2/venv1/lib/python3.12/site-packages/torch/nn/modules/module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ACT/CW2/venv1/lib/python3.12/site-packages/torch/nn/modules/module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: unspecified launch failure\nSearch for `cudaErrorLaunchFailure' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_adpt = Galaxy_CNN_adaptive(128,num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model_adpt.parameters(),lr=10**-3,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54666890",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: unspecified launch failure\nSearch for `cudaErrorLaunchFailure' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# begin training \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_adpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmean_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstd_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m      \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m70\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, trainLoader, testLoader, mean_tensor, std_tensor, criterion, optimizer, device, n_epoch)\u001b[39m\n\u001b[32m     28\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m imgs,lbl \u001b[38;5;129;01min\u001b[39;00m trainLoader:\n\u001b[32m     32\u001b[39m   \u001b[38;5;66;03m# move image to GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   imgs = \u001b[43mimgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m   imgs = (imgs - mean_tensor) / std_tensor \n\u001b[32m     35\u001b[39m   \u001b[38;5;66;03m#rotate images at random\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: unspecified launch failure\nSearch for `cudaErrorLaunchFailure' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# begin training \n",
    "train(model_adpt, train_loader,test_loader,  \n",
    "      mean_tensor,std_tensor,\n",
    "      criterion, \n",
    "      optimizer, device, \n",
    "      n_epoch=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b832a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
