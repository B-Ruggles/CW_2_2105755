{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05015e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 15:53:47.671075: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 15:53:47.722701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 15:53:48.982953: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import sys,os \n",
    "sys.path.append('/home/benr/ACT/CW2/py')\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import get_data,split_data_torch,train_q2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609c2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab2646",
   "metadata": {},
   "source": [
    "# Question 2, Convolutional Neural Network for image recognition \n",
    "In this section the aim is to repeat the same process as question 1 but replace the traditional reandom forest method with a convolutional neural network. The expectation is that due to the CNN's ability to correlate spacial features, it will be a more roubust method of recognising galaxy morphology.\n",
    "\n",
    "The first step will be to load the data in exactly the same way as Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9468cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benr/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n",
      "torch.Size([17736, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the data from functions.py\n",
    "images,labels = get_data()\n",
    "# convert images to pytorch tnesors\n",
    "images = torch.from_numpy(images)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779417f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17736, 3, 256, 256])\n",
      "tensor([0.1675, 0.1626, 0.1589])\n",
      "tensor([0.1287, 0.1180, 0.1116])\n"
     ]
    }
   ],
   "source": [
    "# Move channels: (N,H,W,C) -> (N,C,H,W)\n",
    "images = images.permute(0, 3, 1, 2)      \n",
    "\n",
    "# standardise \n",
    "images = images.float() / 255.0      \n",
    "mean = images.mean(dim=[0,2,3])\n",
    "std = images.std(dim=[0,2,3])\n",
    "print(images.shape)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d76c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11369fd2",
   "metadata": {},
   "source": [
    "For the CNN the lables will need to be encoded into numerical values. \n",
    "Documentation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c2a76",
   "metadata": {},
   "source": [
    "Now we set up the class that will hold the structure of the network. Galaxy_CNN takes the number of input channels, the number of classes (Prediction catagories) and passes them two the different layers of the network. \n",
    "Throughout the process of data being passed through different levels of the CNN we will need to keep trach of the network is change the size of each tensor. This can be done with the following formulas\n",
    "\n",
    "* CNN Output - $$\\frac{H + 2P -K}{s} + 1 $$\n",
    "* Pooling Output - $$\\frac{H-K}{s}  + 1$$\n",
    "\n",
    "H = input height of width of image \n",
    "\n",
    "\n",
    "K = kernel size\n",
    "\n",
    "P = padding size\n",
    "\n",
    "s = stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd26b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c59235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Galaxy_CNN(nn.Module):\n",
    "    def __init__(self, inCH, nCL):  \n",
    "        super(Galaxy_CNN, self).__init__()\n",
    "        # conv blocks\n",
    "        self.conv1 = nn.Conv2d(3, inCH, kernel_size=7, stride=1, padding=4)\n",
    "        self.bn1   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(inCH, inCH*2, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(inCH*2, inCH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.lin = nn.Linear(inCH*16**2, nCL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout(x)\n",
    "            \n",
    "        x = x.view(x.size(0), -1)    \n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8fe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split tensor into training and test sets (see functions.py)\n",
    "I = np.arange(len(labels))\n",
    "xtrn,xtst,ytrn,ytst = split_data_torch(images,labels,I)\n",
    "\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(xtrn, ytrn)\n",
    "test_ds  = TensorDataset(xtst, ytst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=5, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "    test_ds, batch_size=5, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffd8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(labels.unique())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Galaxy_CNN(128,num_classes).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=10**-3,weight_decay=1e-4)\n",
    "\n",
    "#for normalisation \n",
    "mean_tensor = mean.view(1,3,1,1).to(device)\n",
    "std_tensor = std.view(1,3,1,1).to(device)\n",
    "\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5abbf42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model (acc=0.4476)\n",
      "Epoch 1/70 Train loss: 2.1748  Train acc: 0.340  Test acc: 0.448\n",
      "Saved new best model (acc=0.4991)\n",
      "Epoch 2/70 Train loss: 1.4875  Train acc: 0.463  Test acc: 0.499\n",
      "Saved new best model (acc=0.5160)\n",
      "Epoch 3/70 Train loss: 1.3186  Train acc: 0.529  Test acc: 0.516\n",
      "Saved new best model (acc=0.5720)\n",
      "Epoch 4/70 Train loss: 1.2176  Train acc: 0.567  Test acc: 0.572\n",
      "Epoch 5/70 Train loss: 1.1032  Train acc: 0.608  Test acc: 0.572\n",
      "Epoch 6/70 Train loss: 1.0022  Train acc: 0.643  Test acc: 0.572\n",
      "Saved new best model (acc=0.5840)\n",
      "Epoch 7/70 Train loss: 0.9197  Train acc: 0.671  Test acc: 0.584\n",
      "Saved new best model (acc=0.5994)\n",
      "Epoch 8/70 Train loss: 0.8355  Train acc: 0.701  Test acc: 0.599\n",
      "Saved new best model (acc=0.6062)\n",
      "Epoch 9/70 Train loss: 0.7633  Train acc: 0.732  Test acc: 0.606\n",
      "Saved new best model (acc=0.6073)\n",
      "Epoch 10/70 Train loss: 0.7093  Train acc: 0.750  Test acc: 0.607\n",
      "Epoch 11/70 Train loss: 0.6523  Train acc: 0.773  Test acc: 0.594\n",
      "Saved new best model (acc=0.6092)\n",
      "Epoch 12/70 Train loss: 0.5952  Train acc: 0.792  Test acc: 0.609\n",
      "Saved new best model (acc=0.6276)\n",
      "Epoch 13/70 Train loss: 0.5752  Train acc: 0.799  Test acc: 0.628\n",
      "Epoch 14/70 Train loss: 0.5310  Train acc: 0.816  Test acc: 0.621\n",
      "Epoch 15/70 Train loss: 0.4929  Train acc: 0.830  Test acc: 0.616\n",
      "Epoch 16/70 Train loss: 0.4776  Train acc: 0.830  Test acc: 0.625\n",
      "Epoch 17/70 Train loss: 0.4369  Train acc: 0.848  Test acc: 0.615\n",
      "Epoch 18/70 Train loss: 0.4274  Train acc: 0.849  Test acc: 0.604\n",
      "Epoch 19/70 Train loss: 0.4021  Train acc: 0.860  Test acc: 0.614\n",
      "Saved new best model (acc=0.6306)\n",
      "Epoch 20/70 Train loss: 0.3838  Train acc: 0.863  Test acc: 0.631\n",
      "Saved new best model (acc=0.6321)\n",
      "Epoch 21/70 Train loss: 0.3762  Train acc: 0.871  Test acc: 0.632\n",
      "Epoch 22/70 Train loss: 0.3536  Train acc: 0.876  Test acc: 0.623\n",
      "Saved new best model (acc=0.6404)\n",
      "Epoch 23/70 Train loss: 0.3538  Train acc: 0.876  Test acc: 0.640\n",
      "Epoch 24/70 Train loss: 0.3386  Train acc: 0.883  Test acc: 0.619\n",
      "Saved new best model (acc=0.6422)\n",
      "Epoch 25/70 Train loss: 0.3376  Train acc: 0.885  Test acc: 0.642\n",
      "Epoch 26/70 Train loss: 0.3293  Train acc: 0.888  Test acc: 0.619\n",
      "Epoch 27/70 Train loss: 0.3155  Train acc: 0.889  Test acc: 0.628\n",
      "Saved new best model (acc=0.6509)\n",
      "Epoch 28/70 Train loss: 0.3095  Train acc: 0.891  Test acc: 0.651\n",
      "Epoch 29/70 Train loss: 0.2958  Train acc: 0.898  Test acc: 0.635\n",
      "Epoch 30/70 Train loss: 0.2942  Train acc: 0.898  Test acc: 0.649\n",
      "Epoch 31/70 Train loss: 0.2988  Train acc: 0.897  Test acc: 0.648\n",
      "Saved new best model (acc=0.6535)\n",
      "Epoch 32/70 Train loss: 0.2767  Train acc: 0.901  Test acc: 0.654\n",
      "Epoch 33/70 Train loss: 0.2789  Train acc: 0.903  Test acc: 0.638\n",
      "Saved new best model (acc=0.6592)\n",
      "Epoch 34/70 Train loss: 0.2773  Train acc: 0.903  Test acc: 0.659\n",
      "Epoch 35/70 Train loss: 0.2791  Train acc: 0.903  Test acc: 0.638\n",
      "Epoch 36/70 Train loss: 0.2548  Train acc: 0.912  Test acc: 0.648\n",
      "Epoch 37/70 Train loss: 0.2693  Train acc: 0.908  Test acc: 0.654\n",
      "Epoch 38/70 Train loss: 0.2625  Train acc: 0.912  Test acc: 0.644\n",
      "Epoch 39/70 Train loss: 0.2554  Train acc: 0.912  Test acc: 0.654\n",
      "Epoch 40/70 Train loss: 0.2568  Train acc: 0.911  Test acc: 0.658\n",
      "Epoch 41/70 Train loss: 0.2428  Train acc: 0.915  Test acc: 0.657\n",
      "Saved new best model (acc=0.6607)\n",
      "Epoch 42/70 Train loss: 0.2528  Train acc: 0.914  Test acc: 0.661\n",
      "Epoch 43/70 Train loss: 0.2487  Train acc: 0.916  Test acc: 0.648\n",
      "Epoch 44/70 Train loss: 0.2422  Train acc: 0.918  Test acc: 0.660\n",
      "Saved new best model (acc=0.6633)\n",
      "Epoch 45/70 Train loss: 0.2453  Train acc: 0.918  Test acc: 0.663\n",
      "Epoch 46/70 Train loss: 0.2321  Train acc: 0.918  Test acc: 0.648\n",
      "Saved new best model (acc=0.6742)\n",
      "Epoch 47/70 Train loss: 0.2350  Train acc: 0.919  Test acc: 0.674\n",
      "Epoch 48/70 Train loss: 0.2295  Train acc: 0.924  Test acc: 0.653\n",
      "Epoch 49/70 Train loss: 0.2373  Train acc: 0.919  Test acc: 0.661\n",
      "Epoch 50/70 Train loss: 0.2299  Train acc: 0.922  Test acc: 0.655\n",
      "Epoch 51/70 Train loss: 0.2242  Train acc: 0.926  Test acc: 0.656\n",
      "Epoch 52/70 Train loss: 0.2265  Train acc: 0.925  Test acc: 0.652\n",
      "Epoch 53/70 Train loss: 0.2152  Train acc: 0.929  Test acc: 0.651\n",
      "Saved new best model (acc=0.6746)\n",
      "Epoch 54/70 Train loss: 0.2181  Train acc: 0.924  Test acc: 0.675\n",
      "Epoch 55/70 Train loss: 0.2198  Train acc: 0.925  Test acc: 0.659\n",
      "Epoch 56/70 Train loss: 0.2208  Train acc: 0.927  Test acc: 0.672\n",
      "Saved new best model (acc=0.6757)\n",
      "Epoch 57/70 Train loss: 0.2191  Train acc: 0.925  Test acc: 0.676\n",
      "Saved new best model (acc=0.6828)\n",
      "Epoch 58/70 Train loss: 0.2147  Train acc: 0.927  Test acc: 0.683\n",
      "Saved new best model (acc=0.6956)\n",
      "Epoch 59/70 Train loss: 0.2079  Train acc: 0.930  Test acc: 0.696\n",
      "Epoch 60/70 Train loss: 0.2104  Train acc: 0.928  Test acc: 0.668\n",
      "Epoch 61/70 Train loss: 0.2085  Train acc: 0.928  Test acc: 0.670\n",
      "Epoch 62/70 Train loss: 0.2141  Train acc: 0.928  Test acc: 0.659\n",
      "Epoch 63/70 Train loss: 0.2184  Train acc: 0.926  Test acc: 0.666\n",
      "Epoch 64/70 Train loss: 0.1988  Train acc: 0.935  Test acc: 0.650\n",
      "Epoch 65/70 Train loss: 0.2055  Train acc: 0.931  Test acc: 0.694\n",
      "Epoch 66/70 Train loss: 0.2008  Train acc: 0.932  Test acc: 0.666\n"
     ]
    }
   ],
   "source": [
    "train_q2(model, train_loader,test_loader,  \n",
    "      mean_tensor,std_tensor,\n",
    "      criterion, \n",
    "      optimizer, device, \n",
    "      n_epoch=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
