{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05015e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 15:53:47.671075: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 15:53:47.722701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 15:53:48.982953: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import sys,os \n",
    "sys.path.append('/home/benr/ACT/CW2/py')\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import get_data,split_data_torch,train_q2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "#Ensure CUDA is available. \n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab2646",
   "metadata": {},
   "source": [
    "# Question 2, Convolutional Neural Network for image recognition \n",
    "In this section the aim is to repeat the same process as question 1 but replace the traditional reandom forest method with a convolutional neural network (**CNN**). The expectation is that due to the CNN's ability to correlate spacial features, it will be a more robust method of recognising galaxy morphology.\n",
    "\n",
    "The first step will be to load the data in exactly the same way as Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9468cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benr/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n",
      "torch.Size([17736, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the data from functions.py\n",
    "images,labels = get_data()\n",
    "# convert images to pytorch tnesors\n",
    "images = torch.from_numpy(images)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779417f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17736, 3, 256, 256])\n",
      "tensor([0.1675, 0.1626, 0.1589])\n",
      "tensor([0.1287, 0.1180, 0.1116])\n"
     ]
    }
   ],
   "source": [
    "# Move channels: (N,H,W,C) -> (N,C,H,W)\n",
    "images = images.permute(0, 3, 1, 2)      \n",
    "\n",
    "# standardise \n",
    "images = images.float() / 255.0    \n",
    "# The mean and standard deviation will be used later for normalisation   \n",
    "mean = images.mean(dim=[0,2,3])\n",
    "std = images.std(dim=[0,2,3])\n",
    "print(images.shape)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11369fd2",
   "metadata": {},
   "source": [
    "# How do Convolutional Neural Networks work? \n",
    "Images are made up of pixels which have numerical values. The idea behind a convolutional neural network is to slide a 'kernel' (a grid of size (h $\\cdot$ w)) across the image multiplying the values at each postion; this is called a **convolution**. The convolution of the image (I) and the kernel (K) is\n",
    "$$\n",
    "(I*K)_{i,j} = \\sum_{k=1}^{h} \\sum_{l=1}^{w} I_{i+k-1, j+l -1 } K_{kl} \n",
    "$$\n",
    "Each layer of the CNN contains many of these kernels (also called filters). As the kernel slides over the image, the network measures how strongly different sections of the image match the patterns encoded on each kernel. The output of this process is known as a feature map. \n",
    "\n",
    "This idea is similar to the basic MLP with a few key exceptions, \n",
    "\n",
    "\n",
    "* Each node on the feature map corrosponds to a region on the image, so spacial properties are preserved. \n",
    "\n",
    "* In a MLP all nodes are connected, this is not the case for the CNN. Only nodes that are relavent to each other are connected. \n",
    "\n",
    "During training the values inside a kernal are initially set to small random vvalues, the network will update these values using **backpropogation**; this is how the network learns to detect specific image features. Between layers of the CNN there are often **pooling layers**, these are layers that are designed to reduce the size of the image whilst keeping the important information stored in the pixels. This is done by taking an area of the image (an $n$ x $n$ grid) and reducing it to one pixel by taking some average of these pixels.\n",
    "\n",
    "After passing the image through multiple layers of a CNN it will then be passed to a fully connected MLP to predict the catagory of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c2a76",
   "metadata": {},
   "source": [
    "Now we set up the class that will hold the structure of the network. Galaxy_CNN takes the number of input channels, the number of classes (Prediction catagories) and passes them two the different layers of the network. \n",
    "\n",
    "Throughout the process of data being passed through different levels of the CNN we will need to keep track of how each layer changes the size of each image. This can be done with the following formulas\n",
    "\n",
    "* CNN Output - $$\\frac{H + 2P -K}{s} + 1 $$\n",
    "* Pooling Output - $$\\frac{H-K}{s}  + 1$$\n",
    "\n",
    "H = input height or width of image \n",
    "\n",
    "K = kernel size, (n x n) grid\n",
    "\n",
    "P = padding size, zeros added onto the boarder of the image.\n",
    "\n",
    "s = stride, how far the kernal moves after each convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Galaxy_CNN(nn.Module):\n",
    "    def __init__(self, inCH, nCL):  \n",
    "        super(Galaxy_CNN, self).__init__()\n",
    "        # conv blocks\n",
    "        self.conv1 = nn.Conv2d(3, inCH, kernel_size=7, stride=1, padding=4)\n",
    "        # batchnorm is a way of normalising the activation values\n",
    "        self.bn1   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(inCH, inCH*2, kernel_size=5, stride=2, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(inCH*2, inCH, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #dropout is a way of 'turning off' some nodes temporarily, to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        # fully connected final layer \n",
    "        self.lin = nn.Linear(inCH*16**2, nCL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward section passes the batch through the graph\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))# conv1 -> batchnorm -> relu -> pooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))# conv2 -> batchnorm -> relu -> pooling \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))# conv3 -> batchnorm -> relu -> pooling\n",
    "        x = self.dropout(x) \n",
    "        #change shpae of tensor for linear layer (batch size,total features)    \n",
    "        x = x.view(x.size(0), -1)    \n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split tensor into training and test sets (see functions.py)\n",
    "I = np.arange(len(labels))\n",
    "xtrn,xtst,ytrn,ytst = split_data_torch(images,labels,I)\n",
    "\n",
    "\n",
    "# match images and labels in a torch dataset \n",
    "train_ds = TensorDataset(xtrn, ytrn)\n",
    "test_ds  = TensorDataset(xtst, ytst)\n",
    "\n",
    "\n",
    "\n",
    "#create train and test loaders for training\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=5, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "    test_ds, batch_size=5, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# number of catagories \n",
    "num_classes = len(labels.unique())\n",
    "# tell the computer to use the GPU via CUDA \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#The network model \n",
    "model = Galaxy_CNN(128,num_classes).to(device)\n",
    "\n",
    "''' The criterion is the loss function, in this case we are using cross entropy. \n",
    "This function asigns probabilities to each catagory, for example [0,1,0,0...] might be\n",
    "a spiral galaxy. Cross entropy then measures how close the outputs are to this true \n",
    "probability.'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# the method of gradient decent used in backpropogation. \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=10**-3,weight_decay=1e-4)\n",
    "\n",
    "#for normalisation \n",
    "mean_tensor = mean.view(1,3,1,1).to(device)\n",
    "std_tensor = std.view(1,3,1,1).to(device)\n",
    "\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbf42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model (acc=0.4476)\n",
      "Epoch 1/70 Train loss: 2.1748  Train acc: 0.340  Test acc: 0.448\n",
      "Saved new best model (acc=0.4991)\n",
      "Epoch 2/70 Train loss: 1.4875  Train acc: 0.463  Test acc: 0.499\n",
      "Saved new best model (acc=0.5160)\n",
      "Epoch 3/70 Train loss: 1.3186  Train acc: 0.529  Test acc: 0.516\n",
      "Saved new best model (acc=0.5720)\n",
      "Epoch 4/70 Train loss: 1.2176  Train acc: 0.567  Test acc: 0.572\n",
      "Epoch 5/70 Train loss: 1.1032  Train acc: 0.608  Test acc: 0.572\n",
      "Epoch 6/70 Train loss: 1.0022  Train acc: 0.643  Test acc: 0.572\n",
      "Saved new best model (acc=0.5840)\n",
      "Epoch 7/70 Train loss: 0.9197  Train acc: 0.671  Test acc: 0.584\n",
      "Saved new best model (acc=0.5994)\n",
      "Epoch 8/70 Train loss: 0.8355  Train acc: 0.701  Test acc: 0.599\n",
      "Saved new best model (acc=0.6062)\n",
      "Epoch 9/70 Train loss: 0.7633  Train acc: 0.732  Test acc: 0.606\n",
      "Saved new best model (acc=0.6073)\n",
      "Epoch 10/70 Train loss: 0.7093  Train acc: 0.750  Test acc: 0.607\n",
      "Epoch 11/70 Train loss: 0.6523  Train acc: 0.773  Test acc: 0.594\n",
      "Saved new best model (acc=0.6092)\n",
      "Epoch 12/70 Train loss: 0.5952  Train acc: 0.792  Test acc: 0.609\n",
      "Saved new best model (acc=0.6276)\n",
      "Epoch 13/70 Train loss: 0.5752  Train acc: 0.799  Test acc: 0.628\n",
      "Epoch 14/70 Train loss: 0.5310  Train acc: 0.816  Test acc: 0.621\n",
      "Epoch 15/70 Train loss: 0.4929  Train acc: 0.830  Test acc: 0.616\n",
      "Epoch 16/70 Train loss: 0.4776  Train acc: 0.830  Test acc: 0.625\n",
      "Epoch 17/70 Train loss: 0.4369  Train acc: 0.848  Test acc: 0.615\n",
      "Epoch 18/70 Train loss: 0.4274  Train acc: 0.849  Test acc: 0.604\n",
      "Epoch 19/70 Train loss: 0.4021  Train acc: 0.860  Test acc: 0.614\n",
      "Saved new best model (acc=0.6306)\n",
      "Epoch 20/70 Train loss: 0.3838  Train acc: 0.863  Test acc: 0.631\n",
      "Saved new best model (acc=0.6321)\n",
      "Epoch 21/70 Train loss: 0.3762  Train acc: 0.871  Test acc: 0.632\n",
      "Epoch 22/70 Train loss: 0.3536  Train acc: 0.876  Test acc: 0.623\n",
      "Saved new best model (acc=0.6404)\n",
      "Epoch 23/70 Train loss: 0.3538  Train acc: 0.876  Test acc: 0.640\n",
      "Epoch 24/70 Train loss: 0.3386  Train acc: 0.883  Test acc: 0.619\n",
      "Saved new best model (acc=0.6422)\n",
      "Epoch 25/70 Train loss: 0.3376  Train acc: 0.885  Test acc: 0.642\n",
      "Epoch 26/70 Train loss: 0.3293  Train acc: 0.888  Test acc: 0.619\n",
      "Epoch 27/70 Train loss: 0.3155  Train acc: 0.889  Test acc: 0.628\n",
      "Saved new best model (acc=0.6509)\n",
      "Epoch 28/70 Train loss: 0.3095  Train acc: 0.891  Test acc: 0.651\n",
      "Epoch 29/70 Train loss: 0.2958  Train acc: 0.898  Test acc: 0.635\n",
      "Epoch 30/70 Train loss: 0.2942  Train acc: 0.898  Test acc: 0.649\n",
      "Epoch 31/70 Train loss: 0.2988  Train acc: 0.897  Test acc: 0.648\n",
      "Saved new best model (acc=0.6535)\n",
      "Epoch 32/70 Train loss: 0.2767  Train acc: 0.901  Test acc: 0.654\n",
      "Epoch 33/70 Train loss: 0.2789  Train acc: 0.903  Test acc: 0.638\n",
      "Saved new best model (acc=0.6592)\n",
      "Epoch 34/70 Train loss: 0.2773  Train acc: 0.903  Test acc: 0.659\n",
      "Epoch 35/70 Train loss: 0.2791  Train acc: 0.903  Test acc: 0.638\n",
      "Epoch 36/70 Train loss: 0.2548  Train acc: 0.912  Test acc: 0.648\n",
      "Epoch 37/70 Train loss: 0.2693  Train acc: 0.908  Test acc: 0.654\n",
      "Epoch 38/70 Train loss: 0.2625  Train acc: 0.912  Test acc: 0.644\n",
      "Epoch 39/70 Train loss: 0.2554  Train acc: 0.912  Test acc: 0.654\n",
      "Epoch 40/70 Train loss: 0.2568  Train acc: 0.911  Test acc: 0.658\n",
      "Epoch 41/70 Train loss: 0.2428  Train acc: 0.915  Test acc: 0.657\n",
      "Saved new best model (acc=0.6607)\n",
      "Epoch 42/70 Train loss: 0.2528  Train acc: 0.914  Test acc: 0.661\n",
      "Epoch 43/70 Train loss: 0.2487  Train acc: 0.916  Test acc: 0.648\n",
      "Epoch 44/70 Train loss: 0.2422  Train acc: 0.918  Test acc: 0.660\n",
      "Saved new best model (acc=0.6633)\n",
      "Epoch 45/70 Train loss: 0.2453  Train acc: 0.918  Test acc: 0.663\n",
      "Epoch 46/70 Train loss: 0.2321  Train acc: 0.918  Test acc: 0.648\n",
      "Saved new best model (acc=0.6742)\n",
      "Epoch 47/70 Train loss: 0.2350  Train acc: 0.919  Test acc: 0.674\n",
      "Epoch 48/70 Train loss: 0.2295  Train acc: 0.924  Test acc: 0.653\n",
      "Epoch 49/70 Train loss: 0.2373  Train acc: 0.919  Test acc: 0.661\n",
      "Epoch 50/70 Train loss: 0.2299  Train acc: 0.922  Test acc: 0.655\n",
      "Epoch 51/70 Train loss: 0.2242  Train acc: 0.926  Test acc: 0.656\n",
      "Epoch 52/70 Train loss: 0.2265  Train acc: 0.925  Test acc: 0.652\n",
      "Epoch 53/70 Train loss: 0.2152  Train acc: 0.929  Test acc: 0.651\n",
      "Saved new best model (acc=0.6746)\n",
      "Epoch 54/70 Train loss: 0.2181  Train acc: 0.924  Test acc: 0.675\n",
      "Epoch 55/70 Train loss: 0.2198  Train acc: 0.925  Test acc: 0.659\n",
      "Epoch 56/70 Train loss: 0.2208  Train acc: 0.927  Test acc: 0.672\n",
      "Saved new best model (acc=0.6757)\n",
      "Epoch 57/70 Train loss: 0.2191  Train acc: 0.925  Test acc: 0.676\n",
      "Saved new best model (acc=0.6828)\n",
      "Epoch 58/70 Train loss: 0.2147  Train acc: 0.927  Test acc: 0.683\n",
      "Saved new best model (acc=0.6956)\n",
      "Epoch 59/70 Train loss: 0.2079  Train acc: 0.930  Test acc: 0.696\n",
      "Epoch 60/70 Train loss: 0.2104  Train acc: 0.928  Test acc: 0.668\n",
      "Epoch 61/70 Train loss: 0.2085  Train acc: 0.928  Test acc: 0.670\n",
      "Epoch 62/70 Train loss: 0.2141  Train acc: 0.928  Test acc: 0.659\n",
      "Epoch 63/70 Train loss: 0.2184  Train acc: 0.926  Test acc: 0.666\n",
      "Epoch 64/70 Train loss: 0.1988  Train acc: 0.935  Test acc: 0.650\n",
      "Epoch 65/70 Train loss: 0.2055  Train acc: 0.931  Test acc: 0.694\n",
      "Epoch 66/70 Train loss: 0.2008  Train acc: 0.932  Test acc: 0.666\n"
     ]
    }
   ],
   "source": [
    "# calling the train_q2() function from functions.py \n",
    "train_q2(model, train_loader,test_loader,  \n",
    "      mean_tensor,std_tensor,\n",
    "      criterion, \n",
    "      optimizer, device, \n",
    "      n_epoch=70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f3ff2",
   "metadata": {},
   "source": [
    "The training results show that there is an increase in accuracy compared to the random forest method. almost 70% of images have been placed in the correct catagory. This shows that the CNNs ability to recognise spacial features provides a significant improvement over the traditional method. \n",
    "\n",
    "However, looking at the training does show that there are some improvements to be made. After the third epoch the training accuracy significantly overtakes the test accuracy, this is a classic sign of **overfitting**. The network is simply 'memorising' the training images and the weights are being specifically taylored to the training set and not learning to recognise the different features of different types of galaxy. \n",
    "\n",
    "In Question three we will look at how we can use data augmentation to overcome this issue and increase the test accuracy further. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
