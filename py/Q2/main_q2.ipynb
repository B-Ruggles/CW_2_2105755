{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05015e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os \n",
    "sys.path.append('/home/benr/ACT/CW2/py')\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions import get_data, galaxy_type,split_data_torch,train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609c2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab2646",
   "metadata": {},
   "source": [
    "# Question 2, Convolutional Neural Network for image recognition \n",
    "In this section the aim is to repeat the same process as question 1 but replace the traditional reandom forest method with a convolutional neural network. The expectation is that due to the CNN's ability to correlate spacial features, it will be a more roubust method of recognising galaxy morphology.\n",
    "\n",
    "The first step will be to load the data in exactly the same way as Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9468cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benr/.astroNN/datasets/Galaxy10_DECals.h5 was found!\n",
      "torch.Size([17736, 256, 256, 3])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# get the data from functions.py\n",
    "images,labels = get_data()\n",
    "# convert images to pytorch tnesors\n",
    "images = torch.from_numpy(images)\n",
    "labels = torch.from_numpy(labels).long()\n",
    "\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779417f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move channels: (N,H,W,C) -> (N,C,H,W)\n",
    "images = images.permute(0, 3, 1, 2)      \n",
    "\n",
    "# standardise \n",
    "images = images.float() / 255.0      \n",
    "mean = images.mean(dim=[0,2,3])\n",
    "std = images.std(dim=[0,2,3])\n",
    "print(images.shape)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d76c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11369fd2",
   "metadata": {},
   "source": [
    "For the CNN the lables will need to be encoded into numerical values. \n",
    "Documentation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c2a76",
   "metadata": {},
   "source": [
    "Now we set up the class that will hold the structure of the network. Galaxy_CNN takes the number of input channels, the number of classes (Prediction catagories) and passes them two the different layers of the network. \n",
    "Throughout the process of data being passed through different levels of the CNN we will need to keep trach of the network is change the size of each tensor. This can be done with the following formulas\n",
    "\n",
    "* CNN Output - $$\\frac{H + 2P -K}{s} + 1 $$\n",
    "* Pooling Output - $$\\frac{H-K}{s}  + 1$$\n",
    "\n",
    "H = input height of width of image \n",
    "\n",
    "\n",
    "K = kernel size\n",
    "\n",
    "P = padding size\n",
    "\n",
    "s = stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Galaxy_CNN(nn.Module):\n",
    "    def __init__(self, inCH, nCL):  \n",
    "        super(Galaxy_CNN, self).__init__()\n",
    "        # conv blocks\n",
    "        self.conv1 = nn.Conv2d(3, inCH, kernel_size=5, stride=1, padding=4)\n",
    "        self.bn1   = nn.BatchNorm2d(inCH)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(inCH, inCH*2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(inCH*2, inCH*2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(inCH*2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "\n",
    "        # global average pooling \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)   \n",
    "        self.lin = nn.Linear(inCH*2, nCL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.gap(x)              \n",
    "        x = x.view(x.size(0), -1)    \n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split tensor into training and test sets (see functions.py)\n",
    "I = np.arange(len(labels))\n",
    "xtrn,xtst,ytrn,ytst = split_data_torch(images,labels,I)\n",
    "\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(xtrn, ytrn)\n",
    "test_ds  = TensorDataset(xtst, ytst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(labels.unique())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Galaxy_CNN(128,num_classes).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=20**-4,weight_decay=0.0001)\n",
    "\n",
    "#for normalisation \n",
    "mean_tensor = mean.view(1,3,1,1).to(device)\n",
    "std_tensor = std.view(1,3,1,1).to(device)\n",
    "\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbf42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Train loss: 2.2669  Train acc: 0.200  Test acc: 0.248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmean_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstd_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m      \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ACT/CW2/py/functions.py:75\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, trainLoader, testLoader, mean_tensor, std_tensor, criterion, optimizer, device, n_epoch)\u001b[39m\n\u001b[32m     73\u001b[39m optimizer.step()\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# get batch loss \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * imgs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# return position of most likely catagory for each image in batch \u001b[39;00m\n\u001b[32m     77\u001b[39m _,preds = torch.max(outputs,\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader,test_loader,  \n",
    "      mean_tensor,std_tensor,\n",
    "      criterion, \n",
    "      optimizer, device, \n",
    "      n_epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
